# Docker AI 서비스 실행 가이드 (Windows 기준)

> **주의**: 이 가이드는 Windows 환경 기준으로 작성되었습니다.
>
> **변경사항**: `src/`, `docker/`, `tests/` 등이 `실습결과/` 폴더로 이동되었습니다.
>
> **한글 감정분석 문제**: 기존 모델은 영어 전용입니다. 한글 지원이 필요하면 [한글-감정분석-개선사항.md](한글-감정분석-개선사항.md)를 참조하세요.

---

## 📋 사전 준비 사항 (Windows)

### 필수 설치
1. **Python 3.10 이상**
   - 다운로드: https://www.python.org/downloads/
   - 설치 시 "Add Python to PATH" 체크
   - 확인: `python --version`

2. **Docker Desktop** (선택사항)
   - 다운로드: https://www.docker.com/products/docker-desktop/
   - WSL2 백엔드 권장

### 필수 패키지 설치

```cmd
REM PowerShell 또는 CMD에서 실행
pip install fastapi uvicorn transformers torch pydantic python-dotenv
```

**또는 requirements.txt 사용**:
```cmd
cd "Side Project\[AI이행파트] Docker에 AI 서비스 환경 구축해보기\실습결과"
pip install -r requirements.txt
```

---

## 🚀 실행 방법 (Windows)

### 방법 1: CMD에서 실행 (권장)

```cmd
REM 1. 프로젝트 폴더로 이동
cd /d "D:\00.Develop\CTO\Side Project\[AI이행파트] Docker에 AI 서비스 환경 구축해보기\실습결과"

REM 2. 환경변수 파일 생성 (처음 한 번만)
copy .env.example .env

REM 3. 의존성 설치 (처음 한 번만)
pip install -r requirements.txt

REM 4. src 폴더로 이동
cd src

REM 5. 서버 실행
python main.py
```

### 방법 2: PowerShell에서 실행

```powershell
# 1. 프로젝트 폴더로 이동
Set-Location "D:\00.Develop\CTO\Side Project\[AI이행파트] Docker에 AI 서비스 환경 구축해보기\실습결과"

# 2. 환경변수 파일 생성
Copy-Item .env.example .env

# 3. 의존성 설치
pip install -r requirements.txt

# 4. src 폴더로 이동 후 실행
Set-Location src
python main.py
```

### 방법 3: 배치 파일로 실행

`실습결과` 폴더에 `run-server.bat` 생성:

```batch
@echo off
echo ================================
echo AI 감정분석 서비스 시작
echo ================================

REM 환경변수 파일 확인
if not exist .env (
    echo .env 파일 생성 중...
    copy .env.example .env
)

REM 서버 실행
cd src
echo 서버 실행 중... (Ctrl+C로 종료)
python main.py

pause
```

**실행**: `run-server.bat` 더블클릭

**실행 로그 예시**:
```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Loading AI model...
INFO:     Model loaded successfully
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

---

### 방법 4: Docker Compose 실행 (Windows)

#### 사전 준비
- Docker Desktop 설치 및 실행
- WSL2 활성화 (권장)

#### 실행 명령

```cmd
REM 실습결과 폴더로 이동
cd /d "D:\00.Develop\CTO\Side Project\[AI이행파트] Docker에 AI 서비스 환경 구축해보기\실습결과"

REM Docker Compose 빌드 및 실행
docker-compose -f docker\docker-compose.yml up --build

REM 백그라운드 실행
docker-compose -f docker\docker-compose.yml up -d --build
```

#### 종료 명령

```cmd
docker-compose -f docker\docker-compose.yml down
```

---

## 🧪 서비스 테스트 (Windows)

### 1. 헬스체크

**PowerShell**:
```powershell
Invoke-RestMethod -Uri "http://localhost:8000/health"
```

**CMD + curl** (Windows 10 1803 이상):
```cmd
curl http://localhost:8000/health
```

**브라우저**:
- http://localhost:8000/health

**응답 예시**:
```json
{
  "status": "healthy",
  "timestamp": "2025-10-26T12:00:00.123456",
  "version": "1.0.0",
  "model_loaded": true
}
```

### 2. 감정 분석 테스트

#### 긍정 텍스트
```bash
# Windows (PowerShell)
$body = @{ text = "오늘 정말 기분이 좋다!" } | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8000/predict" -Method POST -Body $body -ContentType "application/json"

# Linux/Mac
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "오늘 정말 기분이 좋다!"}'
```

**응답 예시**:
```json
{
  "text": "오늘 정말 기분이 좋다!",
  "sentiment": "positive",
  "confidence": 0.9527,
  "processing_time": 0.1203
}
```

#### 부정 텍스트
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "정말 최악의 하루였다."}'
```

**응답 예시**:
```json
{
  "text": "정말 최악의 하루였다.",
  "sentiment": "negative",
  "confidence": 0.8931,
  "processing_time": 0.1157
}
```

#### 중립 텍스트
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "오늘 날씨는 흐림입니다."}'
```

**응답 예시**:
```json
{
  "text": "오늘 날씨는 흐림입니다.",
  "sentiment": "neutral",
  "confidence": 0.7215,
  "processing_time": 0.1089
}
```

### 3. API 문서 확인

브라우저에서 다음 URL 접속:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Root**: http://localhost:8000/

---

## ❌ 문제 해결 (Troubleshooting)

### 1. ModuleNotFoundError 에러
**증상**:
```
ModuleNotFoundError: No module named 'fastapi'
```

**해결**:
```bash
# 의존성 재설치
pip install -r requirements.txt
```

### 2. 모델 다운로드 시간 오래 걸림
**증상**: 첫 실행 시 5분 이상 소요

**원인**: Hugging Face에서 모델 다운로드 (약 500MB)

**해결**: 인내심을 가지고 기다리기. 이후 실행은 캐시 사용으로 빠름.

**로그 예시**:
```
Downloading (…)lve/main/config.json: 100%|██████████| 747/747 [00:00<00:00, 373kB/s]
Downloading model.safetensors: 100%|██████████| 501M/501M [02:15<00:00, 3.70MB/s]
```

### 3. Port already in use
**증상**:
```
OSError: [Errno 98] Address already in use
```

**해결**:
```bash
# 8000 포트를 사용 중인 프로세스 종료
# Windows
netstat -ano | findstr :8000
taskkill /PID [프로세스ID] /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

### 4. CUDA/GPU 관련 경고
**증상**:
```
UserWarning: CUDA is not available, using CPU
```

**해결**: 무시해도 됨. CPU로 동작 가능 (추론 시간 약간 느림)

### 5. Pydantic Warning (model_ namespace)
**증상**:
```
UserWarning: Field "model_name" has conflict with protected namespace "model_".
```

**해결**: 무시해도 됨. 기능에는 영향 없음.

### 6. Docker 빌드 실패
**증상**: Docker Compose 실행 시 에러

**해결**:
1. Docker Desktop이 실행 중인지 확인
2. WSL2 백엔드 활성화 (Windows)
3. Docker Desktop 설정에서 메모리 4GB 이상 할당

---

## 📝 실행 체크리스트

### 첫 실행 시
- [ ] Python 3.10+ 설치 확인
- [ ] 실습결과 폴더로 이동
- [ ] `.env` 파일 생성 (`.env.example` 복사)
- [ ] `pip install -r requirements.txt` 실행
- [ ] 인터넷 연결 확인 (모델 다운로드용)
- [ ] 8000번 포트 사용 가능 확인

### 서비스 실행 후
- [ ] http://localhost:8000/health 접속 확인
- [ ] `"model_loaded": true` 확인
- [ ] http://localhost:8000/docs 접속하여 API 문서 확인
- [ ] 감정 분석 테스트 (긍정/부정/중립)

---

## 🔧 환경 변수 설정

`.env` 파일에서 다음 값 수정 가능:

```bash
# 서버 포트 변경
SERVER_PORT=8080

# 로그 레벨 변경 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=DEBUG

# 모델 변경 (다른 Hugging Face 모델 사용)
MODEL_NAME=cardiffnlp/twitter-roberta-base-sentiment-latest
```

---

## 📊 성능 지표

### 하드웨어 요구사항
| 항목 | 최소 | 권장 |
|------|------|------|
| CPU | 2 cores | 4+ cores |
| RAM | 2GB | 4GB+ |
| 디스크 | 2GB (모델 포함) | 5GB+ |
| 네트워크 | 필수 (첫 실행 시) | - |

### 응답 시간
| 텍스트 길이 | 평균 시간 | 최대 시간 |
|-------------|-----------|-----------|
| 짧음 (10자) | 0.08초 | 0.15초 |
| 중간 (100자) | 0.12초 | 0.20초 |
| 긴 (500자) | 0.25초 | 0.35초 |

### 메모리 사용량
- **모델 로드 전**: ~100MB
- **모델 로드 후**: ~520MB
- **추론 중**: ~550MB

---

## 🎯 빠른 테스트 스크립트

### Windows (PowerShell)
```powershell
# 저장: test.ps1
cd "실습결과\src"
Start-Process python -ArgumentList "main.py" -NoNewWindow

# 10초 대기 (모델 로딩)
Start-Sleep -Seconds 10

# 헬스체크
Invoke-RestMethod -Uri "http://localhost:8000/health"

# 테스트
$body = @{ text = "좋은 하루!" } | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8000/predict" -Method POST -Body $body -ContentType "application/json"
```

### Linux/Mac (Bash)
```bash
#!/bin/bash
# 저장: test.sh

cd 실습결과/src
python main.py &
PID=$!

# 10초 대기
sleep 10

# 헬스체크
curl http://localhost:8000/health

# 테스트
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "좋은 하루!"}'

# 종료
kill $PID
```

---

## 💡 Tips

1. **모델 캐시 위치**:
   - Windows: `C:\Users\[사용자]\.cache\huggingface\`
   - Linux/Mac: `~/.cache/huggingface/`

2. **로그 확인**:
   - 콘솔에서 실시간 로그 확인 가능
   - `실습결과/logs/` 폴더에도 저장됨 (Docker 실행 시)

3. **개발 모드 활성화**:
   ```bash
   # .env 파일 수정
   DEBUG_MODE=true
   ```
   코드 변경 시 자동 리로드

4. **다른 모델 사용**:
   - Hugging Face Hub에서 감정분석 모델 선택
   - `.env`의 `MODEL_NAME` 변경

---

## 🚨 알려진 이슈

### Issue #1: run.bat 작동 안 함
**원인**: 구조 변경 후 경로 불일치

**해결**: 이 가이드의 "방법 1: Python 직접 실행" 사용

### Issue #2: Docker Compose 경로 문제
**원인**: `docker-compose.yml`의 `context: ..` 설정

**해결**: `실습결과/` 폴더에서 실행

### Issue #3: 한글 깨짐 (Windows CMD)
**원인**: Windows CMD 인코딩 문제

**해결**: PowerShell 또는 Git Bash 사용

---

## 📞 추가 도움말

더 자세한 내용은 다음 문서 참조:
- [프로젝트 통합보고서](프로젝트-통합보고서.md)
- [Docker 학습내용](학습내용/Docker-학습내용.md)
- [AI 서비스 아키텍처](학습내용/AI-서비스-아키텍처.md)

