"""
04. ì„±ëŠ¥ ë¹„êµ ì˜ˆì œ (Baseline vs Advanced Parser)

Baseline Parserì™€ ê³ ê¸‰ Parserì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
- íŒŒì‹± ì†ë„
- ì •í™•ë„
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
"""

import time
import re
from typing import List, Tuple, Dict
from collections import defaultdict


class BaselineParser:
    """
    ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ Baseline Parser
    - ì •ê·œì‹ê³¼ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©
    """

    def __init__(self):
        self.verb_pattern = re.compile(r'\b(is|are|was|were|run|ran|jump|jumped|walk|walked)\b')

    def parse(self, sentence: str) -> Dict:
        """ê°„ë‹¨í•œ ê·œì¹™ìœ¼ë¡œ ë¬¸ì¥ íŒŒì‹±"""
        words = sentence.lower().replace('.', '').split()

        if not words:
            return {'subject': None, 'predicate': None, 'modifiers': []}

        # ì²« ë‹¨ì–´ë¥¼ ì£¼ì–´ë¡œ
        subject = words[0]

        # ë™ì‚¬ ì°¾ê¸°
        predicate = None
        for word in words:
            if self.verb_pattern.match(word):
                predicate = word
                break

        # ë‚˜ë¨¸ì§€ëŠ” ìˆ˜ì‹ì–´
        modifiers = [w for w in words[1:] if w != predicate]

        return {
            'subject': subject,
            'predicate': predicate,
            'modifiers': modifiers
        }


class FrequencyBasedParser:
    """
    ë¹ˆë„ ê¸°ë°˜ í†µê³„ Parser
    - í›ˆë ¨ ë°ì´í„°ì—ì„œ íŒ¨í„´ í•™ìŠµ
    - ê°€ì¥ ë¹ˆë²ˆí•œ íŒ¨í„´ ì ìš©
    """

    def __init__(self):
        self.patterns = defaultdict(int)
        self.trained = False

    def train(self, sentences: List[str]):
        """ë¬¸ì¥ íŒ¨í„´ í•™ìŠµ"""
        for sentence in sentences:
            words = sentence.lower().replace('.', '').split()
            if len(words) >= 2:
                # ê°„ë‹¨í•œ íŒ¨í„´: ì²« 2ê°œ ë‹¨ì–´ì˜ ì¡°í•©
                pattern = f"{words[0]}_{words[1]}"
                self.patterns[pattern] += 1
        self.trained = True

    def parse(self, sentence: str) -> Dict:
        """í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ íŒŒì‹±"""
        words = sentence.lower().replace('.', '').split()

        if not words:
            return {'subject': None, 'predicate': None, 'modifiers': []}

        # íŒ¨í„´ ë§¤ì¹­
        if len(words) >= 2:
            pattern = f"{words[0]}_{words[1]}"
            if pattern in self.patterns:
                # íŒ¨í„´ì´ ìˆìœ¼ë©´ ì²« ë‹¨ì–´ë¥¼ ì£¼ì–´, ë‘ ë²ˆì§¸ë¥¼ ìˆ ì–´ë¡œ
                return {
                    'subject': words[0],
                    'predicate': words[1],
                    'modifiers': words[2:]
                }

        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ê·œì¹™
        return {
            'subject': words[0] if words else None,
            'predicate': words[1] if len(words) > 1 else None,
            'modifiers': words[2:] if len(words) > 2 else []
        }


class RuleBasedParser:
    """
    í–¥ìƒëœ ê·œì¹™ ê¸°ë°˜ Parser
    - ë” ë§ì€ ê·œì¹™ê³¼ ì˜ˆì™¸ ì²˜ë¦¬
    """

    def __init__(self):
        self.verbs = {'is', 'are', 'was', 'were', 'run', 'ran', 'runs',
                     'jump', 'jumped', 'jumps', 'walk', 'walked', 'walks',
                     'eat', 'ate', 'eats', 'sleep', 'slept', 'sleeps'}
        self.determiners = {'the', 'a', 'an'}

    def parse(self, sentence: str) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ íŒŒì‹±"""
        words = sentence.lower().replace('.', '').replace(',', '').split()

        if not words:
            return {'subject': None, 'predicate': None, 'modifiers': []}

        # ê´€ì‚¬ ì œê±° í›„ ì²« ë‹¨ì–´ë¥¼ ì£¼ì–´ë¡œ
        subject_idx = 0
        if words[0] in self.determiners and len(words) > 1:
            subject_idx = 1

        subject = words[subject_idx]

        # ë™ì‚¬ ì°¾ê¸°
        predicate = None
        predicate_idx = -1
        for i, word in enumerate(words):
            if word in self.verbs:
                predicate = word
                predicate_idx = i
                break

        # ìˆ˜ì‹ì–´ ë¶„ë¥˜
        modifiers_before = words[subject_idx + 1:predicate_idx] if predicate_idx > subject_idx + 1 else []
        modifiers_after = words[predicate_idx + 1:] if predicate_idx != -1 and predicate_idx < len(words) - 1 else []

        return {
            'subject': subject,
            'predicate': predicate,
            'modifiers': modifiers_before + modifiers_after
        }


def benchmark_parser(parser, sentences: List[str], parser_name: str) -> Dict:
    """
    íŒŒì„œ ì„±ëŠ¥ ì¸¡ì •

    Returns:
        ì„±ëŠ¥ í†µê³„
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ” {parser_name} ì„±ëŠ¥ ì¸¡ì •")
    print(f"{'=' * 60}")

    # ì†ë„ ì¸¡ì •
    start_time = time.time()

    results = []
    for sentence in sentences:
        result = parser.parse(sentence)
        results.append(result)

    end_time = time.time()
    elapsed_time = end_time - start_time

    # í†µê³„ ê³„ì‚°
    total_sentences = len(sentences)
    parsed_subjects = sum(1 for r in results if r['subject'] is not None)
    parsed_predicates = sum(1 for r in results if r['predicate'] is not None)

    avg_time_per_sentence = (elapsed_time / total_sentences) * 1000  # ms

    stats = {
        'parser_name': parser_name,
        'total_time': elapsed_time,
        'avg_time_per_sentence': avg_time_per_sentence,
        'total_sentences': total_sentences,
        'parsed_subjects': parsed_subjects,
        'parsed_predicates': parsed_predicates,
        'subject_rate': (parsed_subjects / total_sentences) * 100,
        'predicate_rate': (parsed_predicates / total_sentences) * 100,
    }

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
    print(f"  ì „ì²´ ì²˜ë¦¬ ì‹œê°„:        {elapsed_time:.4f}ì´ˆ")
    print(f"  ë¬¸ì¥ë‹¹ í‰ê·  ì‹œê°„:      {avg_time_per_sentence:.4f}ms")
    print(f"  ì´ˆë‹¹ ì²˜ë¦¬ ë¬¸ì¥ ìˆ˜:     {total_sentences / elapsed_time:.0f}ê°œ/ì´ˆ")

    print(f"\nğŸ“ˆ íŒŒì‹± ì„±ê³µë¥ :")
    print(f"  ì£¼ì–´ íŒŒì‹± ì„±ê³µ:        {parsed_subjects}/{total_sentences} ({stats['subject_rate']:.1f}%)")
    print(f"  ìˆ ì–´ íŒŒì‹± ì„±ê³µ:        {parsed_predicates}/{total_sentences} ({stats['predicate_rate']:.1f}%)")

    # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“ ìƒ˜í”Œ íŒŒì‹± ê²°ê³¼ (ì²˜ìŒ 5ê°œ):")
    for i, (sentence, result) in enumerate(zip(sentences[:5], results[:5]), 1):
        print(f"  {i}. \"{sentence}\"")
        print(f"     ì£¼ì–´: {result['subject']}, ìˆ ì–´: {result['predicate']}")

    return stats


def compare_parsers():
    """ì—¬ëŸ¬ íŒŒì„œ ì„±ëŠ¥ ë¹„êµ"""
    print("\n" + "=" * 70)
    print("ğŸ“Š Baseline Parser vs Advanced Parser ì„±ëŠ¥ ë¹„êµ")
    print("=" * 70)

    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ìƒì„±
    sentences = [
        "The cat runs quickly.",
        "A dog jumps high.",
        "The bird sings beautifully.",
        "Children play outside.",
        "The man walks slowly.",
        "A car runs fast.",
        "The teacher is kind.",
        "Students are studying.",
        "The sun is bright.",
        "Flowers are blooming.",
    ] * 100  # 1000ê°œ ë¬¸ì¥

    print(f"\nğŸ“Œ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(sentences)}ê°œ ë¬¸ì¥")

    # 1. Baseline Parser í…ŒìŠ¤íŠ¸
    baseline_parser = BaselineParser()
    baseline_stats = benchmark_parser(baseline_parser, sentences, "Baseline Parser")

    # 2. Frequency-based Parser í…ŒìŠ¤íŠ¸ (ë¨¼ì € í•™ìŠµ)
    freq_parser = FrequencyBasedParser()
    training_data = sentences[:500]  # ì ˆë°˜ìœ¼ë¡œ í•™ìŠµ
    print(f"\nğŸ“ Frequency-based Parser í•™ìŠµ ì¤‘... ({len(training_data)}ê°œ ë¬¸ì¥)")
    freq_parser.train(training_data)
    freq_stats = benchmark_parser(freq_parser, sentences, "Frequency-based Parser")

    # 3. Rule-based Parser í…ŒìŠ¤íŠ¸
    rule_parser = RuleBasedParser()
    rule_stats = benchmark_parser(rule_parser, sentences, "Rule-based Parser")

    # ë¹„êµ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“Š ìµœì¢… ë¹„êµ ê²°ê³¼")
    print("=" * 70)

    all_stats = [baseline_stats, freq_stats, rule_stats]

    print(f"\n{'Parser':<25} {'ì†ë„(ms)':<12} {'ì£¼ì–´ì„±ê³µë¥ ':<12} {'ìˆ ì–´ì„±ê³µë¥ ':<12}")
    print("-" * 70)
    for stats in all_stats:
        print(f"{stats['parser_name']:<25} "
              f"{stats['avg_time_per_sentence']:<12.4f} "
              f"{stats['subject_rate']:<12.1f}% "
              f"{stats['predicate_rate']:<12.1f}%")

    # ìµœê³  ì„±ëŠ¥ íŒŒì„œ ì°¾ê¸°
    print(f"\nğŸ† ì„±ëŠ¥ ìˆœìœ„:")
    fastest = min(all_stats, key=lambda x: x['avg_time_per_sentence'])
    print(f"  ê°€ì¥ ë¹ ë¥¸ íŒŒì„œ:    {fastest['parser_name']} ({fastest['avg_time_per_sentence']:.4f}ms)")

    most_accurate = max(all_stats, key=lambda x: (x['subject_rate'] + x['predicate_rate']) / 2)
    print(f"  ê°€ì¥ ì •í™•í•œ íŒŒì„œ:  {most_accurate['parser_name']} "
          f"(í‰ê·  {(most_accurate['subject_rate'] + most_accurate['predicate_rate']) / 2:.1f}%)")


def accuracy_test():
    """ì •ë‹µ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ì •í™•ë„ ì¸¡ì •"""
    print("\n" + "=" * 70)
    print("ğŸ¯ ì •í™•ë„ í…ŒìŠ¤íŠ¸ (Ground Truth ë¹„êµ)")
    print("=" * 70)

    # ì •ë‹µ ë¼ë²¨ì´ ìˆëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = [
        ("The cat runs.", {'subject': 'cat', 'predicate': 'runs'}),
        ("A dog jumps.", {'subject': 'dog', 'predicate': 'jumps'}),
        ("Birds are singing.", {'subject': 'birds', 'predicate': 'are'}),
        ("The child is playing.", {'subject': 'child', 'predicate': 'is'}),
        ("Trees grow tall.", {'subject': 'trees', 'predicate': 'grow'}),
    ]

    parsers = [
        ("Baseline", BaselineParser()),
        ("Rule-based", RuleBasedParser()),
    ]

    for parser_name, parser in parsers:
        print(f"\n{parser_name} Parser ì •í™•ë„:")

        correct_subject = 0
        correct_predicate = 0

        for sentence, ground_truth in test_data:
            result = parser.parse(sentence)

            if result['subject'] == ground_truth['subject']:
                correct_subject += 1
            if result['predicate'] == ground_truth['predicate']:
                correct_predicate += 1

        total = len(test_data)
        print(f"  ì£¼ì–´ ì •í™•ë„:  {correct_subject}/{total} ({correct_subject/total*100:.1f}%)")
        print(f"  ìˆ ì–´ ì •í™•ë„:  {correct_predicate}/{total} ({correct_predicate/total*100:.1f}%)")


if __name__ == "__main__":
    print("\nâš¡ Parser ì„±ëŠ¥ ë¹„êµ ë° ë²¤ì¹˜ë§ˆí¬")
    print("=" * 70)

    # ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰
    compare_parsers()

    # ì •í™•ë„ í…ŒìŠ¤íŠ¸
    accuracy_test()

    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print("=" * 70)
    print("\nğŸ’¡ ê²°ë¡ :")
    print("  - Baseline ParserëŠ” ê°€ì¥ ë‹¨ìˆœí•˜ì§€ë§Œ ê¸°ë³¸ì ì¸ ê¸°ëŠ¥ ì œê³µ")
    print("  - Rule-based ParserëŠ” ë” ë§ì€ ê·œì¹™ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ")
    print("  - Frequency-based ParserëŠ” í•™ìŠµ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ íŒ¨í„´ ì¸ì‹")
    print("  - ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” Baselineìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ê°œì„ ")
    print("=" * 70)
