# 1.2.04. 데이터 전처리 - 청커(Chunker) 만들기 (1)

> **작성자**: Bern
> **작성일**: 2025-10-25
> **카테고리**: 데이터 전처리

---

## 목차
1. [Chunker의 개념](#1-chunker의-개념)
2. [청크를 나누는 기준](#2-청크를-나누는-기준)
3. [Chunker의 Input/Output 데이터 예시](#3-chunker의-inputoutput-데이터-예시)
4. [다음 단계](#4-다음-단계)

---

## 1. Chunker의 개념

### 1.1. Chunker란?

**Chunker(청커)**는 긴 텍스트를 작은 단위로 분할하는 프로세스입니다. RAG(Retrieval-Augmented Generation) 시스템에서 필수적인 전처리 단계로, 대용량 문서를 효율적으로 처리하고 검색할 수 있도록 만듭니다.

```
[긴 문서] → [Chunker] → [청크1, 청크2, 청크3, ...]
```

### 1.2. Chunking이 필요한 이유

#### 1) LLM의 토큰 제한
- LLM(Large Language Model)은 입력 토큰 수에 제한이 있습니다
- GPT-4: 최대 8K~128K 토큰
- 긴 문서를 한 번에 처리하기 어려움

#### 2) 검색 정확도 향상
- 작은 청크 단위로 임베딩하면 의미적 유사도 검색이 더 정확해집니다
- 관련 없는 내용이 섞이지 않아 노이즈가 줄어듭니다

#### 3) 응답 품질 개선
- 필요한 정보만 포함된 청크를 검색하여 LLM에 제공
- 불필요한 정보로 인한 혼란 방지

#### 4) 처리 비용 절감
- 작은 단위로 나누어 필요한 부분만 처리
- API 호출 비용 및 처리 시간 감소

### 1.3. Chunking의 실무 적용

| 적용 분야 | 설명 |
|----------|------|
| **문서 검색 시스템** | 대량의 문서에서 관련 정보 검색 |
| **챗봇/Q&A 시스템** | 사용자 질문에 맞는 답변 검색 |
| **법률/의료 문서** | 긴 전문 문서의 효율적 처리 |
| **연구 논문 분석** | 논문의 섹션별 분석 |
| **고객 지원** | FAQ, 매뉴얼 등의 효율적 관리 |

---

## 2. 청크를 나누는 기준

### 2.1. 청크 크기 (Chunk Size)

청크의 크기는 **문자 수** 또는 **토큰 수**로 결정합니다.

#### 일반적인 청크 크기 권장사항

| 청크 크기 | 특징 | 적용 사례 |
|---------|------|----------|
| **작은 청크 (100-300자)** | - 정밀한 검색<br>- 문맥 손실 위험 | 짧은 Q&A, 키워드 검색 |
| **중간 청크 (300-800자)** | - 균형잡힌 성능<br>- 가장 일반적 | 일반 문서, 기사, 블로그 |
| **큰 청크 (800-1500자)** | - 문맥 유지<br>- 검색 정밀도 감소 | 기술 문서, 논문 |

```python
# 예시: 청크 크기별 분할
text = "매우 긴 텍스트 내용..." * 100

# 작은 청크 (200자)
small_chunks = [text[i:i+200] for i in range(0, len(text), 200)]

# 중간 청크 (500자)
medium_chunks = [text[i:i+500] for i in range(0, len(text), 500)]

# 큰 청크 (1000자)
large_chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]
```

### 2.2. 청크 오버랩 (Chunk Overlap)

청크 간 중복을 두어 문맥의 연속성을 유지합니다.

```
[문장1 문장2 문장3] 문장4 문장5 문장6
      [문장2 문장3 문장4] 문장5 문장6
            [문장3 문장4 문장5] 문장6
                  [문장4 문장5 문장6]
```

#### 오버랩 비율 권장사항

| 오버랩 비율 | 설명 | 장점 | 단점 |
|-----------|------|------|------|
| **0% (중복 없음)** | 청크 간 중복 없음 | 저장 공간 최소화 | 문맥 단절 위험 |
| **10-20%** | 약간의 중복 | 균형잡힌 접근 | 일반적 사용 |
| **30-50%** | 많은 중복 | 문맥 보존 우수 | 저장 공간 증가 |

```python
def create_chunks_with_overlap(text, chunk_size=500, overlap=100):
    """
    오버랩을 포함한 청크 생성

    Args:
        text: 분할할 텍스트
        chunk_size: 청크 크기 (문자 수)
        overlap: 오버랩 크기 (문자 수)
    """
    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)

        # 다음 청크 시작 위치 = 현재 위치 + (청크 크기 - 오버랩)
        start += (chunk_size - overlap)

    return chunks

# 사용 예시
text = "긴 텍스트 내용..." * 100
chunks = create_chunks_with_overlap(text, chunk_size=500, overlap=100)
print(f"총 청크 수: {len(chunks)}")
```

### 2.3. 구분 기준 (Separator)

텍스트를 나누는 기준을 설정합니다.

#### 주요 구분 기준

| 구분 기준 | 설명 | 예시 |
|---------|------|------|
| **문단** | 이중 줄바꿈 (`\n\n`) | 문단 단위 분할 |
| **문장** | 마침표 (`.`, `!`, `?`) | 문장 단위 분할 |
| **줄** | 단일 줄바꿈 (`\n`) | 줄 단위 분할 |
| **구조적 요소** | 제목, 섹션 등 | 마크다운, HTML |

```python
# 문단 기준 분할
def split_by_paragraph(text):
    return text.split('\n\n')

# 문장 기준 분할
import re

def split_by_sentence(text):
    # 한국어: 마침표, 물음표, 느낌표 뒤의 공백 또는 줄바꿈
    sentences = re.split(r'[.!?]\s+', text)
    return [s.strip() for s in sentences if s.strip()]

# 예시
text = """이것은 첫 번째 문장입니다. 이것은 두 번째 문장입니다!
세 번째 문장도 있습니다? 네, 있습니다."""

paragraphs = split_by_paragraph(text)
sentences = split_by_sentence(text)

print("문단 분할:", paragraphs)
print("문장 분할:", sentences)
```

### 2.4. 토큰 기반 분할

임베딩 모델의 토큰 제한을 고려한 분할

```python
from transformers import AutoTokenizer

def split_by_tokens(text, model_name='jhgan/ko-sroberta-multitask', max_tokens=512):
    """
    토큰 수 기준으로 텍스트 분할

    Args:
        text: 분할할 텍스트
        model_name: 토크나이저 모델명
        max_tokens: 최대 토큰 수
    """
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # 전체 텍스트를 토큰화
    tokens = tokenizer.encode(text, add_special_tokens=False)

    chunks = []
    for i in range(0, len(tokens), max_tokens):
        chunk_tokens = tokens[i:i + max_tokens]
        chunk_text = tokenizer.decode(chunk_tokens)
        chunks.append(chunk_text)

    return chunks

# 사용 예시
text = "긴 문서 내용..." * 200
chunks = split_by_tokens(text, max_tokens=512)
print(f"토큰 기반 청크 수: {len(chunks)}")
```

---

## 3. Chunker의 Input/Output 데이터 예시

### 3.1. Input 데이터 예시

#### 예시 1: 일반 텍스트 문서

```python
input_text = """
농촌진흥청 연구 보고서

제1장. 서론
본 연구는 스마트팜 기술의 현황과 발전 방향을 분석하고자 합니다.
최근 농업 분야에서 ICT 기술의 도입이 급속도로 진행되고 있습니다.

제2장. 스마트팜 기술 개요
스마트팜은 IoT, AI, 빅데이터 등 첨단 기술을 활용하여 농작물의 생육 환경을
자동으로 제어하고 최적화하는 농업 시스템입니다.

2.1 주요 기술 요소
- 환경 센서: 온도, 습도, CO2, 조도 등을 측정
- 자동 제어: 관수, 양액, 온도 등을 자동 조절
- 데이터 분석: 생육 데이터 수집 및 분석

제3장. 실증 사례
경기도 소재 A농장에서는 스마트팜 도입 후 생산성이 30% 향상되었습니다.
"""

print(f"원본 텍스트 길이: {len(input_text)} 문자")
```

#### 예시 2: PDF에서 추출한 텍스트

```python
# PDF 파서를 통해 추출된 텍스트
input_from_pdf = {
    'filename': 'smartfarm_report_2024.pdf',
    'total_pages': 50,
    'text': """
    [페이지 1]
    농촌진흥청 연구보고서
    스마트팜 기술 현황과 전망

    [페이지 2]
    목차
    1. 서론 ..................... 3
    2. 스마트팜 기술 개요 ......... 5
    3. 실증 사례 ................. 15
    """,
    'metadata': {
        'author': 'RDA',
        'created_date': '2024-10-20',
        'category': 'Research Report'
    }
}
```

### 3.2. Output 데이터 예시

#### 예시 1: 기본 청크 분할 결과

```python
# 문단 기준 분할 결과
output_chunks_basic = [
    {
        'chunk_id': 0,
        'text': '농촌진흥청 연구 보고서\n\n제1장. 서론\n본 연구는 스마트팜 기술의 현황과 발전 방향을 분석하고자 합니다.\n최근 농업 분야에서 ICT 기술의 도입이 급속도로 진행되고 있습니다.',
        'length': 105
    },
    {
        'chunk_id': 1,
        'text': '제2장. 스마트팜 기술 개요\n스마트팜은 IoT, AI, 빅데이터 등 첨단 기술을 활용하여 농작물의 생육 환경을 자동으로 제어하고 최적화하는 농업 시스템입니다.',
        'length': 98
    },
    {
        'chunk_id': 2,
        'text': '2.1 주요 기술 요소\n- 환경 센서: 온도, 습도, CO2, 조도 등을 측정\n- 자동 제어: 관수, 양액, 온도 등을 자동 조절\n- 데이터 분석: 생육 데이터 수집 및 분석',
        'length': 102
    },
    {
        'chunk_id': 3,
        'text': '제3장. 실증 사례\n경기도 소재 A농장에서는 스마트팜 도입 후 생산성이 30% 향상되었습니다.',
        'length': 56
    }
]

# 출력
for chunk in output_chunks_basic:
    print(f"\n[청크 {chunk['chunk_id']}] ({chunk['length']}자)")
    print(chunk['text'])
    print("-" * 50)
```

#### 예시 2: 메타데이터 포함 청크

```python
# 메타데이터와 함께 저장된 청크
output_chunks_with_metadata = [
    {
        'chunk_id': 'chunk_0',
        'text': '제1장. 서론\n본 연구는 스마트팜 기술의 현황과 발전 방향을 분석하고자 합니다.',
        'metadata': {
            'source': 'smartfarm_report_2024.pdf',
            'page': 1,
            'chapter': '제1장',
            'chunk_index': 0,
            'total_chunks': 4,
            'char_count': 65,
            'created_at': '2024-10-25',
            'overlap_with_next': True
        }
    },
    {
        'chunk_id': 'chunk_1',
        'text': '제2장. 스마트팜 기술 개요\n스마트팜은 IoT, AI, 빅데이터 등 첨단 기술을 활용하여 농작물의 생육 환경을 자동으로 제어하고 최적화하는 농업 시스템입니다.',
        'metadata': {
            'source': 'smartfarm_report_2024.pdf',
            'page': 2,
            'chapter': '제2장',
            'chunk_index': 1,
            'total_chunks': 4,
            'char_count': 98,
            'created_at': '2024-10-25',
            'overlap_with_next': True
        }
    }
]

# JSON 형태로 출력
import json
print(json.dumps(output_chunks_with_metadata, ensure_ascii=False, indent=2))
```

#### 예시 3: 실전 Chunker 구현

```python
class SimpleChunker:
    """간단한 청커 구현 예시"""

    def __init__(self, chunk_size=500, overlap=100, separator='\n\n'):
        """
        Args:
            chunk_size: 청크의 최대 크기 (문자 수)
            overlap: 청크 간 중복 크기 (문자 수)
            separator: 우선 분할 기준 (문단, 문장 등)
        """
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.separator = separator

    def chunk(self, text, metadata=None):
        """
        텍스트를 청크로 분할

        Args:
            text: 분할할 텍스트
            metadata: 원본 문서 메타데이터

        Returns:
            청크 리스트 (딕셔너리 형태)
        """
        chunks = []

        # 1. 먼저 separator로 분할
        segments = text.split(self.separator)

        current_chunk = ""
        chunk_index = 0

        for segment in segments:
            # 현재 청크에 세그먼트 추가 시 크기 확인
            if len(current_chunk) + len(segment) <= self.chunk_size:
                current_chunk += segment + self.separator
            else:
                # 현재 청크 저장
                if current_chunk.strip():
                    chunks.append({
                        'chunk_id': f'chunk_{chunk_index}',
                        'text': current_chunk.strip(),
                        'metadata': {
                            'chunk_index': chunk_index,
                            'char_count': len(current_chunk.strip()),
                            'original_metadata': metadata
                        }
                    })
                    chunk_index += 1

                # 새 청크 시작 (오버랩 적용)
                if self.overlap > 0 and current_chunk:
                    # 이전 청크의 마지막 일부를 포함
                    overlap_text = current_chunk[-self.overlap:]
                    current_chunk = overlap_text + segment + self.separator
                else:
                    current_chunk = segment + self.separator

        # 마지막 청크 저장
        if current_chunk.strip():
            chunks.append({
                'chunk_id': f'chunk_{chunk_index}',
                'text': current_chunk.strip(),
                'metadata': {
                    'chunk_index': chunk_index,
                    'char_count': len(current_chunk.strip()),
                    'original_metadata': metadata
                }
            })

        # 전체 청크 수 메타데이터 추가
        for chunk in chunks:
            chunk['metadata']['total_chunks'] = len(chunks)

        return chunks

# 사용 예시
chunker = SimpleChunker(chunk_size=200, overlap=50, separator='\n\n')

sample_text = """
제1장. 서론
본 연구는 스마트팜 기술의 현황과 발전 방향을 분석하고자 합니다.

제2장. 스마트팜 기술 개요
스마트팜은 IoT, AI, 빅데이터 등 첨단 기술을 활용하여 농작물의 생육 환경을 자동으로 제어하고 최적화하는 농업 시스템입니다.

제3장. 실증 사례
경기도 소재 A농장에서는 스마트팜 도입 후 생산성이 30% 향상되었습니다.
"""

metadata = {
    'source': 'smartfarm_report.pdf',
    'author': 'RDA',
    'created_date': '2024-10-25'
}

chunks = chunker.chunk(sample_text, metadata)

print(f"\n=== Chunking 결과 ===")
print(f"총 청크 수: {len(chunks)}\n")

for chunk in chunks:
    print(f"[{chunk['chunk_id']}]")
    print(f"문자 수: {chunk['metadata']['char_count']}")
    print(f"텍스트: {chunk['text'][:100]}...")
    print("-" * 60)
```

### 3.3. Input → Chunker → Output 전체 흐름

```python
# 전체 프로세스 예시
def chunking_pipeline():
    """청킹 파이프라인 전체 흐름"""

    # Step 1: Input - 원본 문서 로드
    print("Step 1: 원본 문서 로드")
    document = {
        'filename': 'research_report.pdf',
        'text': """
        농촌진흥청 연구보고서

        제1장. 서론
        본 연구는 스마트팜 기술을 분석합니다.

        제2장. 기술 개요
        스마트팜은 ICT 기술을 활용한 농업 시스템입니다.
        """,
        'metadata': {
            'author': 'RDA',
            'date': '2024-10-25'
        }
    }
    print(f"원본 문서 길이: {len(document['text'])} 문자\n")

    # Step 2: Chunking
    print("Step 2: 청킹 수행")
    chunker = SimpleChunker(chunk_size=100, overlap=20)
    chunks = chunker.chunk(document['text'], document['metadata'])
    print(f"생성된 청크 수: {len(chunks)}\n")

    # Step 3: Output - 청크 확인
    print("Step 3: 청크 결과 확인")
    for i, chunk in enumerate(chunks):
        print(f"\n청크 {i + 1}:")
        print(f"  ID: {chunk['chunk_id']}")
        print(f"  길이: {chunk['metadata']['char_count']}자")
        print(f"  내용: {chunk['text'][:50]}...")

    return chunks

# 실행
result_chunks = chunking_pipeline()
```

---

## 4. 다음 단계

청커의 기본 개념과 청크를 나누는 기준을 이해했다면, 다음 단계에서는 **다양한 청킹 기법**을 배워보겠습니다.

**다음 문서**: [1.2.05. 데이터 전처리 - 청커(Chunker) 만들기 (2)](./1.2.05.데이터%20전처리%20-%20청커(Chunker)%20만들기(2).md)

### 다음에 배울 내용
- Fixed-size 분할
- Rule-based 분할
- Structure-aware 분할
- Semantic 분할 (의미 기반)
- 각 방법의 장단점 비교
- 실전 예시 코드

---

**참고 자료**:
- LangChain Text Splitters: https://python.langchain.com/docs/modules/data_connection/document_transformers/
- Hugging Face Tokenizers: https://huggingface.co/docs/tokenizers/
- OpenAI Token 계산기: https://platform.openai.com/tokenizer
