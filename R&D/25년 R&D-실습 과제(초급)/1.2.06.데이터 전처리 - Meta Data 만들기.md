# 1.2.06. 데이터 전처리 - Meta Data 만들기

> **학습 목표**: 문서 처리 시 메타데이터의 중요성을 이해하고, 실무에서 활용할 수 있는 메타데이터 생성 기법을 습득합니다.

---

## 목차

1. [메타데이터 정의](#1-메타데이터-정의)
2. [실무 활용 이유](#2-실무-활용-이유)
3. [사용 분야](#3-사용-분야)
4. [필요성](#4-필요성)
5. [Meta Data 예시](#5-meta-data-예시)
6. [사용 시나리오](#6-사용-시나리오)
7. [예시 코드](#7-예시-코드)
8. [실무 노하우](#8-실무-노하우)

---

## 1. 메타데이터 정의

### 1.1 메타데이터란?

**메타데이터(Metadata)는 "데이터에 대한 데이터"**입니다. 즉, 실제 콘텐츠 외에 그 콘텐츠를 설명하고 관리하는 데 필요한 부가 정보를 의미합니다.

### 1.2 메타데이터의 구성 요소

문서 처리에서 메타데이터는 일반적으로 다음과 같은 정보를 포함합니다:

| 구분 | 설명 | 예시 |
|------|------|------|
| **식별 정보** | 문서를 고유하게 식별 | document_id, file_name, hash |
| **시간 정보** | 생성/수정 시간 | created_at, updated_at, processed_at |
| **출처 정보** | 문서의 원본 출처 | source_url, source_system, author |
| **구조 정보** | 문서의 물리적 구조 | page_number, section, chunk_index |
| **처리 정보** | 데이터 처리 관련 | parser_version, encoding, file_size |
| **분류 정보** | 문서의 의미적 분류 | category, tags, department |
| **품질 정보** | 데이터 품질 지표 | confidence_score, is_valid, error_count |

### 1.3 메타데이터 vs 데이터

```
┌─────────────────────────────────────────────────┐
│  문서 예시: 연구 보고서                           │
├─────────────────────────────────────────────────┤
│                                                 │
│  [데이터 (Content)]                             │
│  "2024년 농업 연구 결과에 따르면 벼 수확량이      │
│   전년 대비 15% 증가했습니다..."                 │
│                                                 │
│  [메타데이터 (Metadata)]                        │
│  - document_id: "RDA_2024_001"                  │
│  - title: "2024 벼 수확량 연구 보고서"           │
│  - author: "농촌진흥청"                          │
│  - created_at: "2024-10-24"                     │
│  - page_number: 1                               │
│  - file_type: "PDF"                             │
│  - category: "농업 연구"                        │
│                                                 │
└─────────────────────────────────────────────────┘
```

---

## 2. 실무 활용 이유

### 2.1 효율적인 문서 관리

메타데이터를 통해 수천, 수만 개의 문서를 체계적으로 관리할 수 있습니다.

**메타데이터 없을 때:**
```
❌ 문제점:
- "어떤 파일이 최신 버전인지 모름"
- "이 문서가 어디서 왔는지 추적 불가"
- "처리된 문서와 미처리 문서 구분 어려움"
```

**메타데이터 있을 때:**
```
✅ 해결:
- version: "2.0", updated_at: "2024-10-24" → 최신 버전 즉시 확인
- source_url: "https://..." → 출처 추적 가능
- processing_status: "completed" → 처리 상태 명확
```

### 2.2 검색 및 필터링 성능 향상

메타데이터를 활용하면 전체 문서 내용을 읽지 않고도 빠르게 필터링할 수 있습니다.

```python
# 메타데이터 기반 빠른 필터링
filtered_docs = [
    doc for doc in documents
    if doc.metadata['category'] == '농업 연구'
    and doc.metadata['year'] == 2024
    and doc.metadata['department'] == 'RDA'
]

# 전체 텍스트 검색보다 100배 이상 빠름!
```

### 2.3 AI 모델 성능 개선

LLM(대형 언어 모델)에 메타데이터를 함께 제공하면 더 정확한 답변을 얻을 수 있습니다.

**메타데이터 없이 질문:**
```
User: "벼 수확량이 얼마나 증가했나요?"
LLM: "죄송합니다. 어떤 연도의 데이터를 원하시나요?"
```

**메타데이터와 함께 질문:**
```
Context: [메타데이터] year: 2024, source: "RDA 연구보고서"
        [내용] "벼 수확량이 전년 대비 15% 증가"

User: "벼 수확량이 얼마나 증가했나요?"
LLM: "2024년 RDA 연구보고서에 따르면, 벼 수확량이 전년 대비 15% 증가했습니다."
```

### 2.4 데이터 품질 관리

메타데이터를 통해 데이터 품질을 모니터링하고 문제를 추적할 수 있습니다.

```python
# 품질 관련 메타데이터
metadata = {
    'parsing_success': True,
    'text_length': 1234,
    'encoding': 'utf-8',
    'error_count': 0,
    'confidence_score': 0.95,
    'validation_status': 'passed'
}
```

---

## 3. 사용 분야

### 3.1 문서 관리 시스템 (DMS)

- **전자문서 보관**: 공공기관, 기업의 문서 아카이빙
- **법률 문서 관리**: 계약서, 소송 문서의 체계적 관리
- **의료 기록 관리**: 환자 기록, 진료 차트 관리

### 3.2 검색 엔진

- **기업 내부 검색**: 사내 문서 검색 시스템
- **도서관 시스템**: 도서 및 논문 검색
- **전자상거래**: 상품 정보 검색 및 필터링

### 3.3 AI/ML 파이프라인

- **RAG (Retrieval-Augmented Generation)**: LLM에 문서 검색 결합
- **문서 분류**: 자동 카테고리 분류 시스템
- **감정 분석**: 고객 리뷰, 설문조사 분석

### 3.4 데이터 거버넌스

- **규정 준수**: GDPR, 개인정보보호법 대응
- **감사 추적**: 데이터 접근 및 수정 이력 관리
- **데이터 계보**: 데이터의 출처 및 변환 과정 추적

---

## 4. 필요성

### 4.1 대용량 문서 처리

**문제 상황:**
```
회사에 10만 개의 PDF 문서가 있습니다.
"2023년 마케팅 부서의 Q4 보고서"를 찾아야 합니다.
```

**메타데이터 없이:**
- 10만 개 파일을 모두 열어서 확인 → 며칠 소요
- 파일명만으로는 정확한 내용 파악 불가

**메타데이터 활용:**
```python
query = {
    'department': 'Marketing',
    'year': 2023,
    'quarter': 'Q4',
    'doc_type': 'Report'
}

results = metadata_db.search(query)  # 0.1초 내 검색 완료
```

### 4.2 멀티모달 데이터 통합

다양한 형식의 데이터를 통합 관리할 때 메타데이터가 필수입니다.

```python
# 다양한 형식의 문서를 메타데이터로 통합
documents = [
    {
        'content': '...',
        'metadata': {
            'source_type': 'PDF',
            'file_name': 'report.pdf',
            'page': 1
        }
    },
    {
        'content': '...',
        'metadata': {
            'source_type': 'Excel',
            'file_name': 'data.xlsx',
            'sheet': 'Sheet1',
            'row_range': '1-100'
        }
    },
    {
        'content': '...',
        'metadata': {
            'source_type': 'Web',
            'url': 'https://example.com',
            'crawled_at': '2024-10-24'
        }
    }
]
```

### 4.3 버전 관리 및 이력 추적

문서의 변경 이력을 추적하여 언제, 누가, 무엇을 변경했는지 알 수 있습니다.

```python
metadata_history = {
    'document_id': 'DOC_001',
    'versions': [
        {
            'version': '1.0',
            'created_at': '2024-01-15',
            'created_by': 'user_a',
            'changes': 'Initial version'
        },
        {
            'version': '2.0',
            'created_at': '2024-10-24',
            'created_by': 'user_b',
            'changes': 'Updated statistics'
        }
    ]
}
```

### 4.4 컨텍스트 유지

문서를 작은 조각(chunk)으로 나눌 때, 메타데이터를 통해 원본 문맥을 유지할 수 있습니다.

```python
# 문서를 청크로 분할할 때 메타데이터로 맥락 유지
original_document = "10페이지 분량의 연구 보고서"

chunks = [
    {
        'text': '1장 내용...',
        'metadata': {
            'doc_id': 'RDA_001',
            'chapter': 1,
            'page': 1,
            'total_pages': 10
        }
    },
    {
        'text': '2장 내용...',
        'metadata': {
            'doc_id': 'RDA_001',
            'chapter': 2,
            'page': 3,
            'total_pages': 10
        }
    }
]
```

---

## 5. Meta Data 예시

### 5.1 기본 메타데이터 구조

```python
# 최소한의 메타데이터
basic_metadata = {
    'document_id': 'DOC_20241024_001',
    'file_name': 'research_report.pdf',
    'created_at': '2024-10-24T14:30:00',
    'file_size': 2048576,  # bytes
    'file_type': 'PDF'
}
```

### 5.2 확장된 메타데이터 구조

```python
# 실무에서 사용하는 상세한 메타데이터
extended_metadata = {
    # 식별 정보
    'document_id': 'RDA_2024_RESEARCH_001',
    'file_name': '2024_rice_harvest_report.pdf',
    'hash': 'sha256:abc123...',

    # 시간 정보
    'created_at': '2024-10-24T14:30:00+09:00',
    'updated_at': '2024-10-24T15:45:00+09:00',
    'processed_at': '2024-10-24T16:00:00+09:00',

    # 출처 정보
    'source': 'Rural Development Administration',
    'author': 'Bern',
    'department': 'Agricultural Research',
    'source_url': 'https://rda.go.kr/reports/2024/001',

    # 문서 구조 정보
    'total_pages': 15,
    'page_number': 1,
    'section': 'Introduction',
    'chapter': 1,

    # 내용 분류
    'category': 'Research Report',
    'subcategory': 'Agriculture',
    'tags': ['rice', 'harvest', '2024', 'statistics'],
    'language': 'ko',

    # 처리 정보
    'file_type': 'PDF',
    'file_size': 2048576,
    'encoding': 'UTF-8',
    'parser_version': '2.0.1',
    'processing_status': 'completed',

    # 품질 정보
    'text_length': 3456,
    'confidence_score': 0.98,
    'has_errors': False,
    'validation_passed': True,

    # 비즈니스 정보
    'year': 2024,
    'quarter': 'Q3',
    'region': 'Korea',
    'classification_level': 'Public'
}
```

### 5.3 청크 단위 메타데이터

문서를 작은 조각으로 나눌 때 사용하는 메타데이터:

```python
chunk_metadata = {
    # 원본 문서 정보
    'document_id': 'RDA_2024_001',
    'original_file': '2024_rice_harvest_report.pdf',

    # 청크 위치 정보
    'chunk_id': 'RDA_2024_001_chunk_003',
    'chunk_index': 3,
    'total_chunks': 45,

    # 텍스트 위치
    'page_number': 5,
    'start_char': 1234,
    'end_char': 2345,
    'paragraph_index': 2,

    # 청크 생성 정보
    'chunk_method': 'recursive_character',
    'chunk_size': 1000,
    'chunk_overlap': 200,
    'created_at': '2024-10-24T16:05:00',

    # 의미적 정보
    'section_title': '2. 연구 방법',
    'context_summary': '벼 재배 방법 및 측정 기준 설명',
    'keywords': ['벼', '재배', '측정']
}
```

### 5.4 벡터 임베딩 메타데이터

AI 검색에 사용되는 벡터 임베딩과 함께 저장하는 메타데이터:

```python
vector_metadata = {
    # 기본 문서 정보
    'document_id': 'RDA_2024_001',
    'chunk_id': 'RDA_2024_001_chunk_003',

    # 임베딩 정보
    'embedding_model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
    'embedding_dimension': 768,
    'embedding_created_at': '2024-10-24T16:10:00',

    # 검색 필터용
    'category': 'Research Report',
    'year': 2024,
    'tags': ['rice', 'agriculture'],

    # 원본 참조
    'source_file': '2024_rice_harvest_report.pdf',
    'page': 5,

    # 품질 정보
    'text_quality_score': 0.95
}
```

---

## 6. 사용 시나리오

### 6.1 LLM 입력 전

#### 시나리오: RAG (Retrieval-Augmented Generation) 시스템

**상황:**
사용자가 "2024년 벼 수확량 증가율을 알려줘"라고 질문합니다.

**메타데이터 활용 과정:**

```python
# 1단계: 메타데이터 기반 사전 필터링
def filter_relevant_documents(query, all_documents):
    """
    전체 문서에서 관련 문서만 필터링
    - 벡터 검색 전에 실행하여 검색 범위를 좁힘
    """
    filtered = []

    for doc in all_documents:
        metadata = doc['metadata']

        # 메타데이터 조건 검사
        if (metadata.get('year') == 2024 and
            metadata.get('category') == 'Research Report' and
            '벼' in metadata.get('tags', []) and
            metadata.get('language') == 'ko'):
            filtered.append(doc)

    return filtered
    # 결과: 10만 개 → 50개로 축소 (99.95% 감소!)

# 2단계: 필터링된 문서에 대해서만 벡터 검색 수행
relevant_docs = filter_relevant_documents(user_query, all_documents)
search_results = vector_search(user_query, relevant_docs)

# 3단계: 메타데이터를 포함하여 LLM에 전달
context = []
for result in search_results:
    context.append({
        'content': result['text'],
        'source': result['metadata']['source_file'],
        'page': result['metadata']['page'],
        'year': result['metadata']['year'],
        'author': result['metadata']['author']
    })

prompt = f"""
다음 정보를 바탕으로 질문에 답변하세요.

[문서 정보]
출처: {context[0]['source']}
작성자: {context[0]['author']}
연도: {context[0]['year']}
페이지: {context[0]['page']}

[내용]
{context[0]['content']}

[질문]
2024년 벼 수확량 증가율을 알려줘
"""

# LLM 응답: "농촌진흥청의 2024년 연구 보고서 5페이지에 따르면,
#           벼 수확량이 전년 대비 15% 증가했습니다."
```

**메타데이터 활용 효과:**
- ✅ 검색 속도: 100배 향상 (10만 개 → 50개 검색)
- ✅ 검색 정확도: 90% 이상
- ✅ 출처 명시: 답변의 신뢰성 확보
- ✅ 비용 절감: LLM 토큰 사용량 90% 감소

### 6.2 검색 기반 LLM 서비스

#### 시나리오: 기업 내부 문서 Q&A 시스템

**요구사항:**
- 수만 개의 내부 문서에서 특정 정보 검색
- 부서별, 연도별, 문서 타입별 필터링 필요
- 답변 시 출처를 명확히 제시

**구현 예시:**

```python
class DocumentQASystem:
    def __init__(self, vector_db, metadata_db):
        self.vector_db = vector_db
        self.metadata_db = metadata_db

    def search(self, query, filters=None):
        """
        메타데이터 필터와 벡터 검색 결합
        """
        # 1. 메타데이터 필터 적용
        if filters:
            candidate_ids = self.metadata_db.filter(filters)
        else:
            candidate_ids = None

        # 2. 후보 문서에서만 벡터 검색
        results = self.vector_db.search(
            query=query,
            filter_ids=candidate_ids,
            top_k=5
        )

        # 3. 메타데이터와 함께 결과 반환
        enriched_results = []
        for result in results:
            metadata = self.metadata_db.get(result['id'])
            enriched_results.append({
                'text': result['text'],
                'score': result['score'],
                'metadata': metadata
            })

        return enriched_results

    def generate_answer(self, query, user_filters):
        """
        검색 결과를 바탕으로 LLM 답변 생성
        """
        # 검색 실행
        results = self.search(query, filters=user_filters)

        # 컨텍스트 구성
        context_parts = []
        for i, result in enumerate(results, 1):
            meta = result['metadata']
            context_parts.append(f"""
            [문서 {i}]
            출처: {meta['file_name']}
            부서: {meta['department']}
            작성일: {meta['created_at']}
            페이지: {meta.get('page', 'N/A')}

            내용: {result['text']}
            """)

        # LLM 프롬프트
        prompt = f"""
        다음 문서들을 참고하여 질문에 답변하세요.
        답변 시 반드시 출처를 명시하세요.

        {''.join(context_parts)}

        질문: {query}

        답변 형식:
        - 답변 내용
        - 출처: [문서명, 페이지]
        """

        return self.llm.generate(prompt)

# 사용 예시
qa_system = DocumentQASystem(vector_db, metadata_db)

# 사용자 쿼리
answer = qa_system.generate_answer(
    query="2024년 마케팅 예산이 얼마인가요?",
    user_filters={
        'department': 'Marketing',
        'year': 2024,
        'doc_type': 'Budget Report'
    }
)

# 결과:
# "2024년 마케팅 예산은 50억 원입니다.
#  [출처: 2024_marketing_budget.pdf, 3페이지, 마케팅부, 2024-01-15]"
```

### 6.3 오류 추적 및 품질 관리

#### 시나리오: 문서 처리 파이프라인 품질 모니터링

**요구사항:**
- 대량의 문서를 자동으로 처리
- 처리 오류 발생 시 빠른 추적 및 복구
- 데이터 품질 모니터링

**구현 예시:**

```python
class DocumentProcessor:
    def __init__(self):
        self.error_log = []
        self.quality_metrics = []

    def process_document(self, file_path):
        """
        문서 처리 및 메타데이터 생성
        """
        start_time = datetime.now()

        # 메타데이터 초기화
        metadata = {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'processing_started_at': start_time.isoformat(),
            'processing_status': 'in_progress'
        }

        try:
            # 1. 파일 읽기
            with open(file_path, 'rb') as f:
                content = f.read()

            metadata['file_size'] = len(content)
            metadata['file_hash'] = hashlib.sha256(content).hexdigest()

            # 2. 파싱
            text = self.parse_document(content)
            metadata['text_length'] = len(text)

            # 3. 품질 검사
            quality_score = self.check_quality(text)
            metadata['quality_score'] = quality_score
            metadata['quality_passed'] = quality_score > 0.7

            # 4. 오류 검사
            errors = self.detect_errors(text)
            metadata['error_count'] = len(errors)
            metadata['has_errors'] = len(errors) > 0

            if errors:
                metadata['errors'] = errors
                self.error_log.append({
                    'file': file_path,
                    'errors': errors,
                    'timestamp': datetime.now().isoformat()
                })

            # 5. 처리 완료
            metadata['processing_status'] = 'completed'
            metadata['processing_completed_at'] = datetime.now().isoformat()

            # 처리 시간 계산
            duration = (datetime.now() - start_time).total_seconds()
            metadata['processing_duration_seconds'] = duration

        except Exception as e:
            # 오류 발생 시 메타데이터에 기록
            metadata['processing_status'] = 'failed'
            metadata['error_message'] = str(e)
            metadata['error_type'] = type(e).__name__
            metadata['processing_failed_at'] = datetime.now().isoformat()

            # 에러 로깅
            self.error_log.append({
                'file': file_path,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })

            raise

        # 품질 메트릭 저장
        self.quality_metrics.append({
            'file': file_path,
            'quality_score': metadata.get('quality_score', 0),
            'error_count': metadata.get('error_count', 0),
            'processing_time': metadata.get('processing_duration_seconds', 0)
        })

        return text, metadata

    def get_quality_report(self):
        """
        전체 처리 품질 리포트 생성
        """
        if not self.quality_metrics:
            return "No documents processed"

        total_docs = len(self.quality_metrics)
        avg_quality = sum(m['quality_score'] for m in self.quality_metrics) / total_docs
        total_errors = sum(m['error_count'] for m in self.quality_metrics)
        avg_time = sum(m['processing_time'] for m in self.quality_metrics) / total_docs

        report = f"""
        ===== 문서 처리 품질 리포트 =====

        총 처리 문서: {total_docs}개
        평균 품질 점수: {avg_quality:.2f}
        총 오류 건수: {total_errors}건
        평균 처리 시간: {avg_time:.2f}초

        오류 발생 파일:
        """

        for error in self.error_log:
            report += f"\n- {error['file']}: {error.get('error', error.get('errors'))}"

        return report

    def retry_failed_documents(self):
        """
        실패한 문서 재처리
        """
        failed_docs = [
            error['file'] for error in self.error_log
        ]

        print(f"재처리 대상: {len(failed_docs)}개")

        for doc_path in failed_docs:
            print(f"재처리 중: {doc_path}")
            try:
                self.process_document(doc_path)
                print(f"  ✅ 성공")
            except Exception as e:
                print(f"  ❌ 실패: {e}")

# 사용 예시
processor = DocumentProcessor()

# 배치 처리
documents = ['doc1.pdf', 'doc2.pdf', 'doc3.pdf']
for doc in documents:
    try:
        text, metadata = processor.process_document(doc)
        print(f"✅ {doc}: 처리 완료 (품질: {metadata['quality_score']:.2f})")
    except Exception as e:
        print(f"❌ {doc}: 처리 실패 - {e}")

# 품질 리포트 출력
print(processor.get_quality_report())

# 실패한 문서 재처리
processor.retry_failed_documents()
```

**메타데이터를 통한 품질 관리 효과:**
- ✅ **즉시 오류 추적**: 어떤 파일에서 오류 발생했는지 바로 확인
- ✅ **품질 모니터링**: 처리 품질을 실시간으로 모니터링
- ✅ **선택적 재처리**: 실패한 문서만 골라서 재처리
- ✅ **성능 분석**: 처리 시간, 오류율 등 통계 분석

---

## 7. 예시 코드

### 7.1 기본 메타데이터 생성

```python
import os
import hashlib
from datetime import datetime

def generate_basic_metadata(file_path):
    """
    파일의 기본 메타데이터 생성

    Args:
        file_path (str): 대상 파일 경로

    Returns:
        dict: 기본 메타데이터
    """
    # 파일 존재 확인
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    # 파일 정보 수집
    stat = os.stat(file_path)

    # 파일 해시 생성 (중복 확인용)
    with open(file_path, 'rb') as f:
        file_hash = hashlib.sha256(f.read()).hexdigest()

    # 메타데이터 구성
    metadata = {
        # 식별 정보
        'file_name': os.path.basename(file_path),
        'file_path': os.path.abspath(file_path),
        'file_hash': file_hash,

        # 파일 속성
        'file_size': stat.st_size,
        'file_extension': os.path.splitext(file_path)[1],

        # 시간 정보
        'created_at': datetime.fromtimestamp(stat.st_ctime).isoformat(),
        'modified_at': datetime.fromtimestamp(stat.st_mtime).isoformat(),
        'processed_at': datetime.now().isoformat()
    }

    return metadata

# 사용 예시
metadata = generate_basic_metadata('data/RDA.pdf')
print(metadata)
```

### 7.2 PDF 문서 메타데이터 추출

```python
from pypdf import PdfReader
import os
from datetime import datetime

def extract_pdf_metadata(pdf_path):
    """
    PDF 파일에서 메타데이터 추출

    Args:
        pdf_path (str): PDF 파일 경로

    Returns:
        dict: PDF 메타데이터
    """
    metadata = {}

    try:
        # PDF 열기
        with open(pdf_path, 'rb') as f:
            reader = PdfReader(f)

            # 기본 정보
            metadata['file_name'] = os.path.basename(pdf_path)
            metadata['file_path'] = os.path.abspath(pdf_path)
            metadata['file_size'] = os.path.getsize(pdf_path)
            metadata['file_type'] = 'PDF'

            # PDF 속성
            metadata['total_pages'] = len(reader.pages)
            metadata['is_encrypted'] = reader.is_encrypted

            # PDF 메타데이터 (있는 경우)
            pdf_metadata = reader.metadata
            if pdf_metadata:
                metadata['pdf_title'] = pdf_metadata.get('/Title', 'N/A')
                metadata['pdf_author'] = pdf_metadata.get('/Author', 'N/A')
                metadata['pdf_subject'] = pdf_metadata.get('/Subject', 'N/A')
                metadata['pdf_creator'] = pdf_metadata.get('/Creator', 'N/A')
                metadata['pdf_producer'] = pdf_metadata.get('/Producer', 'N/A')
                metadata['pdf_creation_date'] = pdf_metadata.get('/CreationDate', 'N/A')

            # 첫 페이지 텍스트 미리보기
            if len(reader.pages) > 0:
                first_page_text = reader.pages[0].extract_text()
                metadata['text_preview'] = first_page_text[:200]  # 첫 200자
                metadata['first_page_length'] = len(first_page_text)

            # 처리 시간
            metadata['extracted_at'] = datetime.now().isoformat()

    except Exception as e:
        metadata['error'] = str(e)
        metadata['extraction_failed'] = True

    return metadata

# 사용 예시
pdf_metadata = extract_pdf_metadata('../data/RDA.pdf')

print("=" * 60)
print("PDF 메타데이터")
print("=" * 60)
for key, value in pdf_metadata.items():
    print(f"{key}: {value}")
```

### 7.3 텍스트 청킹 시 메타데이터 생성

```python
def create_chunks_with_metadata(text, document_id, chunk_size=1000, chunk_overlap=200):
    """
    텍스트를 청크로 나누고 각 청크에 메타데이터 추가

    Args:
        text (str): 원본 텍스트
        document_id (str): 문서 고유 ID
        chunk_size (int): 청크 크기
        chunk_overlap (int): 청크 간 중복 크기

    Returns:
        list: 메타데이터가 포함된 청크 리스트
    """
    chunks = []
    start = 0
    chunk_index = 0

    while start < len(text):
        # 청크 추출
        end = start + chunk_size
        chunk_text = text[start:end]

        # 메타데이터 생성
        metadata = {
            # 청크 식별
            'chunk_id': f"{document_id}_chunk_{chunk_index:04d}",
            'document_id': document_id,
            'chunk_index': chunk_index,

            # 청크 위치
            'start_char': start,
            'end_char': end,
            'chunk_length': len(chunk_text),

            # 청크 설정
            'chunk_size': chunk_size,
            'chunk_overlap': chunk_overlap,

            # 처리 정보
            'created_at': datetime.now().isoformat()
        }

        # 청크와 메타데이터 저장
        chunks.append({
            'text': chunk_text,
            'metadata': metadata
        })

        # 다음 청크 시작 위치 (오버랩 고려)
        start += chunk_size - chunk_overlap
        chunk_index += 1

    # 전체 청크 개수 업데이트
    total_chunks = len(chunks)
    for chunk in chunks:
        chunk['metadata']['total_chunks'] = total_chunks

    return chunks

# 사용 예시
sample_text = """
농촌진흥청의 2024년 벼 수확량 연구 결과에 따르면,
올해 벼 수확량이 전년 대비 15% 증가한 것으로 나타났습니다.
이는 기후 변화에 대응한 신품종 개발과 재배 기술 개선의 결과입니다.
""" * 10  # 긴 텍스트 시뮬레이션

chunks = create_chunks_with_metadata(
    text=sample_text,
    document_id='RDA_2024_001',
    chunk_size=200,
    chunk_overlap=50
)

print(f"총 {len(chunks)}개의 청크 생성됨\n")
print("첫 번째 청크:")
print(f"텍스트: {chunks[0]['text'][:100]}...")
print(f"메타데이터: {chunks[0]['metadata']}")
```

### 7.4 종합 메타데이터 생성 클래스

```python
import os
import hashlib
from datetime import datetime
from typing import Dict, Any, List

class MetadataGenerator:
    """
    문서 처리 시 메타데이터를 자동으로 생성하는 클래스
    """

    def __init__(self, source_system: str = "Unknown"):
        """
        Args:
            source_system (str): 데이터 출처 시스템명
        """
        self.source_system = source_system
        self.version = "1.0.0"

    def generate_document_metadata(
        self,
        file_path: str,
        category: str = None,
        tags: List[str] = None,
        custom_metadata: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        문서의 전체 메타데이터 생성

        Args:
            file_path: 문서 파일 경로
            category: 문서 카테고리
            tags: 태그 리스트
            custom_metadata: 사용자 정의 메타데이터

        Returns:
            완전한 메타데이터 딕셔너리
        """
        # 기본 파일 정보
        base_metadata = self._get_file_metadata(file_path)

        # 분류 정보
        if category:
            base_metadata['category'] = category
        if tags:
            base_metadata['tags'] = tags

        # 처리 정보
        base_metadata['source_system'] = self.source_system
        base_metadata['metadata_version'] = self.version
        base_metadata['generated_at'] = datetime.now().isoformat()

        # 사용자 정의 메타데이터 병합
        if custom_metadata:
            base_metadata.update(custom_metadata)

        return base_metadata

    def _get_file_metadata(self, file_path: str) -> Dict[str, Any]:
        """파일의 기본 메타데이터 추출"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        stat = os.stat(file_path)

        with open(file_path, 'rb') as f:
            content = f.read()
            file_hash = hashlib.sha256(content).hexdigest()

        return {
            'file_name': os.path.basename(file_path),
            'file_path': os.path.abspath(file_path),
            'file_size': stat.st_size,
            'file_extension': os.path.splitext(file_path)[1],
            'file_hash': file_hash,
            'created_at': datetime.fromtimestamp(stat.st_ctime).isoformat(),
            'modified_at': datetime.fromtimestamp(stat.st_mtime).isoformat()
        }

    def generate_chunk_metadata(
        self,
        document_metadata: Dict[str, Any],
        chunk_text: str,
        chunk_index: int,
        total_chunks: int,
        start_char: int,
        end_char: int,
        additional_info: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        청크 단위 메타데이터 생성

        Args:
            document_metadata: 원본 문서 메타데이터
            chunk_text: 청크 텍스트
            chunk_index: 청크 인덱스
            total_chunks: 전체 청크 개수
            start_char: 시작 문자 위치
            end_char: 종료 문자 위치
            additional_info: 추가 정보

        Returns:
            청크 메타데이터
        """
        chunk_metadata = {
            # 원본 문서 정보
            'document_id': document_metadata.get('file_hash', 'unknown'),
            'source_file': document_metadata.get('file_name'),

            # 청크 정보
            'chunk_id': f"{document_metadata.get('file_hash', 'unknown')[:8]}_chunk_{chunk_index:04d}",
            'chunk_index': chunk_index,
            'total_chunks': total_chunks,

            # 위치 정보
            'start_char': start_char,
            'end_char': end_char,
            'chunk_length': len(chunk_text),

            # 타임스탬프
            'created_at': datetime.now().isoformat(),

            # 원본 문서의 주요 메타데이터 상속
            'category': document_metadata.get('category'),
            'tags': document_metadata.get('tags'),
            'source_system': document_metadata.get('source_system')
        }

        if additional_info:
            chunk_metadata.update(additional_info)

        return chunk_metadata

    def validate_metadata(self, metadata: Dict[str, Any]) -> tuple[bool, List[str]]:
        """
        메타데이터 유효성 검사

        Args:
            metadata: 검사할 메타데이터

        Returns:
            (is_valid, error_messages)
        """
        errors = []

        # 필수 필드 확인
        required_fields = ['file_name', 'generated_at']
        for field in required_fields:
            if field not in metadata:
                errors.append(f"Missing required field: {field}")

        # 파일 크기 확인
        if 'file_size' in metadata and metadata['file_size'] <= 0:
            errors.append("Invalid file_size: must be positive")

        # 날짜 형식 확인
        if 'generated_at' in metadata:
            try:
                datetime.fromisoformat(metadata['generated_at'])
            except ValueError:
                errors.append("Invalid datetime format for 'generated_at'")

        return (len(errors) == 0, errors)

# 사용 예시
generator = MetadataGenerator(source_system="RDA Document System")

# 1. 문서 메타데이터 생성
doc_metadata = generator.generate_document_metadata(
    file_path='../data/RDA.pdf',
    category='Research Report',
    tags=['agriculture', 'rice', '2024'],
    custom_metadata={
        'department': 'Agricultural Research',
        'year': 2024,
        'author': 'Bern'
    }
)

print("=" * 60)
print("문서 메타데이터")
print("=" * 60)
for key, value in doc_metadata.items():
    print(f"{key}: {value}")

# 2. 청크 메타데이터 생성
sample_text = "농촌진흥청의 연구 결과..."
chunk_metadata = generator.generate_chunk_metadata(
    document_metadata=doc_metadata,
    chunk_text=sample_text,
    chunk_index=0,
    total_chunks=10,
    start_char=0,
    end_char=len(sample_text),
    additional_info={'section': 'Introduction'}
)

print("\n" + "=" * 60)
print("청크 메타데이터")
print("=" * 60)
for key, value in chunk_metadata.items():
    print(f"{key}: {value}")

# 3. 메타데이터 유효성 검사
is_valid, errors = generator.validate_metadata(doc_metadata)
print(f"\n메타데이터 유효성: {'✅ 통과' if is_valid else '❌ 실패'}")
if errors:
    print("오류:")
    for error in errors:
        print(f"  - {error}")
```

### 7.5 메타데이터를 활용한 문서 검색

```python
class MetadataSearchEngine:
    """
    메타데이터 기반 문서 검색 엔진
    """

    def __init__(self):
        self.documents = []

    def add_document(self, text: str, metadata: Dict[str, Any]):
        """문서 추가"""
        self.documents.append({
            'text': text,
            'metadata': metadata
        })

    def search(self, filters: Dict[str, Any] = None, text_query: str = None) -> List[Dict]:
        """
        메타데이터 필터와 텍스트 쿼리로 검색

        Args:
            filters: 메타데이터 필터 조건
            text_query: 텍스트 검색어

        Returns:
            검색 결과 리스트
        """
        results = self.documents.copy()

        # 1. 메타데이터 필터 적용
        if filters:
            results = [
                doc for doc in results
                if self._match_filters(doc['metadata'], filters)
            ]

        # 2. 텍스트 검색 적용
        if text_query:
            results = [
                doc for doc in results
                if text_query.lower() in doc['text'].lower()
            ]

        return results

    def _match_filters(self, metadata: Dict, filters: Dict) -> bool:
        """메타데이터가 필터 조건과 일치하는지 확인"""
        for key, value in filters.items():
            if key not in metadata:
                return False

            # 리스트 타입 (tags 등)은 교집합 확인
            if isinstance(value, list) and isinstance(metadata[key], list):
                if not set(value) & set(metadata[key]):  # 교집합이 없으면
                    return False
            # 일반 값은 완전 일치 확인
            elif metadata[key] != value:
                return False

        return True

    def get_statistics(self) -> Dict[str, Any]:
        """문서 통계 정보"""
        if not self.documents:
            return {}

        categories = {}
        total_size = 0

        for doc in self.documents:
            meta = doc['metadata']

            # 카테고리별 집계
            category = meta.get('category', 'Unknown')
            categories[category] = categories.get(category, 0) + 1

            # 총 파일 크기
            total_size += meta.get('file_size', 0)

        return {
            'total_documents': len(self.documents),
            'categories': categories,
            'total_size_bytes': total_size,
            'total_size_mb': round(total_size / (1024 * 1024), 2)
        }

# 사용 예시
search_engine = MetadataSearchEngine()

# 문서 추가
search_engine.add_document(
    text="2024년 벼 수확량이 전년 대비 15% 증가했습니다.",
    metadata={
        'file_name': 'report_2024.pdf',
        'category': 'Research Report',
        'tags': ['rice', 'harvest', '2024'],
        'year': 2024,
        'department': 'Agricultural Research',
        'file_size': 1024000
    }
)

search_engine.add_document(
    text="2023년 농업 기술 발전 현황을 보고합니다.",
    metadata={
        'file_name': 'tech_2023.pdf',
        'category': 'Technology Report',
        'tags': ['agriculture', 'technology'],
        'year': 2023,
        'department': 'Technology',
        'file_size': 2048000
    }
)

# 검색 1: 메타데이터 필터만
results = search_engine.search(filters={
    'year': 2024,
    'category': 'Research Report'
})
print(f"2024년 연구 보고서: {len(results)}건")
for result in results:
    print(f"  - {result['metadata']['file_name']}")

# 검색 2: 텍스트 + 메타데이터
results = search_engine.search(
    filters={'tags': ['rice']},
    text_query='증가'
)
print(f"\n'벼' 관련 문서 중 '증가' 포함: {len(results)}건")

# 통계
stats = search_engine.get_statistics()
print(f"\n통계:")
print(f"  총 문서: {stats['total_documents']}건")
print(f"  카테고리별: {stats['categories']}")
print(f"  총 크기: {stats['total_size_mb']} MB")
```

---

## 8. 실무 노하우

### 8.1 메타데이터 설계 원칙

#### 원칙 1: 필수 vs 선택 분리

```python
# ✅ 좋은 예: 필수 메타데이터는 간결하게
required_metadata = {
    'document_id': 'DOC_001',        # 필수
    'created_at': '2024-10-24',      # 필수
    'file_type': 'PDF'               # 필수
}

optional_metadata = {
    'author': 'Bern',                # 선택
    'tags': ['research'],            # 선택
    'custom_field': 'value'          # 선택
}

# ❌ 나쁜 예: 모든 필드를 필수로 강제
metadata = {
    'field1': 'value',
    'field2': 'value',
    'field3': 'value',
    # ... 50개 필드 (대부분 불필요)
}
```

#### 원칙 2: 검색에 최적화된 필드 설계

```python
# ✅ 좋은 예: 검색/필터링에 유용한 구조
metadata = {
    'year': 2024,                    # 정수형 → 범위 검색 가능
    'category': 'Research',          # 문자열 → 정확한 매칭
    'tags': ['rice', 'harvest'],     # 리스트 → 다중 태그 검색
    'created_date': '2024-10-24',    # 날짜 → 기간 검색
}

# ❌ 나쁜 예: 검색 어려운 구조
metadata = {
    'info': '2024년 Research 보고서, 태그: rice, harvest'  # 모두 한 문자열에
}
```

#### 원칙 3: 표준 형식 사용

```python
# ✅ 좋은 예: ISO 표준 사용
metadata = {
    'created_at': '2024-10-24T14:30:00+09:00',  # ISO 8601
    'language': 'ko',                            # ISO 639-1
    'country': 'KR',                             # ISO 3166-1
}

# ❌ 나쁜 예: 비표준 형식
metadata = {
    'created_at': '2024년 10월 24일 오후 2시 30분',  # 파싱 어려움
    'language': '한국어',                           # 표준 아님
}
```

### 8.2 성능 최적화

#### 노하우 1: 메타데이터 인덱싱

자주 검색하는 필드는 반드시 인덱싱하세요.

```python
# 예: MongoDB 인덱스 생성
collection.create_index([
    ('category', 1),      # 카테고리 인덱스
    ('year', 1),          # 연도 인덱스
    ('tags', 1),          # 태그 인덱스
    ('created_at', -1)    # 생성일 내림차순 인덱스
])

# 복합 인덱스 (자주 함께 검색되는 필드)
collection.create_index([
    ('category', 1),
    ('year', -1)
])
```

#### 노하우 2: 메타데이터 캐싱

```python
from functools import lru_cache
import hashlib

class MetadataCache:
    """메타데이터 캐시"""

    def __init__(self, max_size=1000):
        self.cache = {}
        self.max_size = max_size

    def get_metadata(self, file_path):
        """캐시에서 메타데이터 조회"""
        # 파일 해시로 캐시 키 생성
        cache_key = self._get_cache_key(file_path)

        if cache_key in self.cache:
            return self.cache[cache_key]

        # 캐시 미스 → 메타데이터 생성
        metadata = self._generate_metadata(file_path)

        # 캐시 저장 (크기 제한)
        if len(self.cache) >= self.max_size:
            # 가장 오래된 항목 제거 (LRU)
            oldest = next(iter(self.cache))
            del self.cache[oldest]

        self.cache[cache_key] = metadata
        return metadata

    def _get_cache_key(self, file_path):
        """파일 경로 + 수정 시간으로 캐시 키 생성"""
        mtime = os.path.getmtime(file_path)
        return hashlib.md5(f"{file_path}_{mtime}".encode()).hexdigest()

    def _generate_metadata(self, file_path):
        """실제 메타데이터 생성 (무거운 작업)"""
        # ... 메타데이터 생성 로직
        pass
```

#### 노하우 3: 선택적 메타데이터 로딩

```python
def get_metadata(doc_id, fields=None):
    """
    필요한 메타데이터 필드만 조회

    Args:
        doc_id: 문서 ID
        fields: 조회할 필드 리스트 (None이면 전체)
    """
    if fields is None:
        # 전체 메타데이터 조회
        return db.documents.find_one({'_id': doc_id})
    else:
        # 일부 필드만 조회 (성능 향상)
        projection = {field: 1 for field in fields}
        return db.documents.find_one({'_id': doc_id}, projection)

# 사용 예
# ✅ 빠름: 필요한 필드만
light_metadata = get_metadata('DOC_001', fields=['title', 'year'])

# ❌ 느림: 불필요한 데이터까지 모두 로드
full_metadata = get_metadata('DOC_001')  # 100개 필드 모두 로드
```

### 8.3 데이터 품질 관리

#### 노하우 1: 메타데이터 검증 로직

```python
from typing import Dict, Any, List
from datetime import datetime

class MetadataValidator:
    """메타데이터 유효성 검사기"""

    def __init__(self):
        self.validation_rules = {
            'document_id': self._validate_document_id,
            'created_at': self._validate_datetime,
            'file_size': self._validate_file_size,
            'category': self._validate_category,
            'tags': self._validate_tags,
        }

        self.valid_categories = [
            'Research Report',
            'Technology Report',
            'Manual',
            'Policy Document'
        ]

    def validate(self, metadata: Dict[str, Any]) -> tuple[bool, List[str]]:
        """
        메타데이터 유효성 검사

        Returns:
            (is_valid, error_messages)
        """
        errors = []

        # 필수 필드 확인
        required_fields = ['document_id', 'created_at', 'file_type']
        for field in required_fields:
            if field not in metadata:
                errors.append(f"Missing required field: {field}")

        # 각 필드별 검증
        for field, validator in self.validation_rules.items():
            if field in metadata:
                is_valid, error_msg = validator(metadata[field])
                if not is_valid:
                    errors.append(f"{field}: {error_msg}")

        return (len(errors) == 0, errors)

    def _validate_document_id(self, value: str) -> tuple[bool, str]:
        """문서 ID 검증"""
        if not isinstance(value, str):
            return False, "Must be string"
        if len(value) < 5:
            return False, "Must be at least 5 characters"
        if not value.replace('_', '').replace('-', '').isalnum():
            return False, "Must contain only alphanumeric characters, _, -"
        return True, ""

    def _validate_datetime(self, value: str) -> tuple[bool, str]:
        """날짜시간 검증"""
        try:
            datetime.fromisoformat(value)
            return True, ""
        except:
            return False, "Invalid ISO format datetime"

    def _validate_file_size(self, value: int) -> tuple[bool, str]:
        """파일 크기 검증"""
        if not isinstance(value, int):
            return False, "Must be integer"
        if value <= 0:
            return False, "Must be positive"
        if value > 1024 * 1024 * 1024:  # 1GB
            return False, "File too large (max 1GB)"
        return True, ""

    def _validate_category(self, value: str) -> tuple[bool, str]:
        """카테고리 검증"""
        if value not in self.valid_categories:
            return False, f"Must be one of {self.valid_categories}"
        return True, ""

    def _validate_tags(self, value: List[str]) -> tuple[bool, str]:
        """태그 검증"""
        if not isinstance(value, list):
            return False, "Must be list"
        if len(value) > 10:
            return False, "Too many tags (max 10)"
        for tag in value:
            if not isinstance(tag, str):
                return False, "All tags must be strings"
        return True, ""

# 사용 예
validator = MetadataValidator()

metadata = {
    'document_id': 'RDA_2024_001',
    'created_at': '2024-10-24T14:30:00+09:00',
    'file_type': 'PDF',
    'file_size': 1024000,
    'category': 'Research Report',
    'tags': ['rice', 'harvest']
}

is_valid, errors = validator.validate(metadata)
if is_valid:
    print("✅ 메타데이터 유효성 검사 통과")
else:
    print("❌ 메타데이터 오류:")
    for error in errors:
        print(f"  - {error}")
```

#### 노하우 2: 자동 메타데이터 보강

```python
def enrich_metadata(metadata: Dict[str, Any]) -> Dict[str, Any]:
    """
    기본 메타데이터를 자동으로 보강
    """
    enriched = metadata.copy()

    # 1. 파일명에서 정보 추출
    file_name = metadata.get('file_name', '')

    # 연도 추출 (예: "report_2024.pdf" → year: 2024)
    import re
    year_match = re.search(r'(20\d{2})', file_name)
    if year_match and 'year' not in enriched:
        enriched['year'] = int(year_match.group(1))

    # 2. 파일 확장자로 MIME 타입 추가
    ext_to_mime = {
        '.pdf': 'application/pdf',
        '.txt': 'text/plain',
        '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    }

    ext = os.path.splitext(file_name)[1].lower()
    if ext in ext_to_mime and 'mime_type' not in enriched:
        enriched['mime_type'] = ext_to_mime[ext]

    # 3. 타임스탬프를 다양한 형식으로 변환
    if 'created_at' in metadata:
        dt = datetime.fromisoformat(metadata['created_at'])
        enriched['created_year'] = dt.year
        enriched['created_month'] = dt.month
        enriched['created_quarter'] = (dt.month - 1) // 3 + 1
        enriched['created_weekday'] = dt.strftime('%A')

    # 4. 파일 크기를 인간 친화적 형식으로
    if 'file_size' in metadata:
        size = metadata['file_size']
        if size < 1024:
            enriched['file_size_human'] = f"{size} B"
        elif size < 1024 * 1024:
            enriched['file_size_human'] = f"{size / 1024:.1f} KB"
        else:
            enriched['file_size_human'] = f"{size / (1024 * 1024):.1f} MB"

    return enriched

# 사용 예
basic_metadata = {
    'file_name': 'research_report_2024.pdf',
    'created_at': '2024-10-24T14:30:00+09:00',
    'file_size': 2048576
}

enriched = enrich_metadata(basic_metadata)
print("보강된 메타데이터:")
for key, value in enriched.items():
    print(f"  {key}: {value}")
```

### 8.4 버전 관리

#### 노하우: 메타데이터 버전 관리

```python
class VersionedMetadata:
    """버전 관리가 포함된 메타데이터"""

    def __init__(self, document_id: str):
        self.document_id = document_id
        self.versions = []

    def add_version(self, metadata: Dict[str, Any], changed_by: str, change_note: str = ""):
        """새 버전 추가"""
        version = {
            'version_number': len(self.versions) + 1,
            'metadata': metadata.copy(),
            'changed_by': changed_by,
            'changed_at': datetime.now().isoformat(),
            'change_note': change_note
        }
        self.versions.append(version)

    def get_latest(self) -> Dict[str, Any]:
        """최신 버전 조회"""
        if not self.versions:
            return {}
        return self.versions[-1]['metadata']

    def get_version(self, version_number: int) -> Dict[str, Any]:
        """특정 버전 조회"""
        if 1 <= version_number <= len(self.versions):
            return self.versions[version_number - 1]['metadata']
        return {}

    def get_history(self) -> List[Dict[str, Any]]:
        """변경 이력 조회"""
        history = []
        for ver in self.versions:
            history.append({
                'version': ver['version_number'],
                'changed_by': ver['changed_by'],
                'changed_at': ver['changed_at'],
                'note': ver['change_note']
            })
        return history

    def rollback(self, version_number: int, changed_by: str):
        """특정 버전으로 롤백"""
        if 1 <= version_number <= len(self.versions):
            old_metadata = self.versions[version_number - 1]['metadata']
            self.add_version(
                metadata=old_metadata,
                changed_by=changed_by,
                change_note=f"Rolled back to version {version_number}"
            )

# 사용 예
vm = VersionedMetadata(document_id='DOC_001')

# 버전 1
vm.add_version(
    metadata={'title': 'Initial Report', 'status': 'draft'},
    changed_by='user_a',
    change_note='Initial creation'
)

# 버전 2
vm.add_version(
    metadata={'title': 'Updated Report', 'status': 'review'},
    changed_by='user_b',
    change_note='Updated title and status'
)

# 최신 버전 조회
latest = vm.get_latest()
print(f"최신 버전: {latest}")

# 변경 이력
history = vm.get_history()
print("\n변경 이력:")
for h in history:
    print(f"  v{h['version']}: {h['note']} (by {h['changed_by']})")
```

### 8.5 실전 팁

#### 팁 1: 메타데이터 정규화

```python
def normalize_metadata(metadata: Dict[str, Any]) -> Dict[str, Any]:
    """
    메타데이터 정규화
    - 문자열 공백 제거
    - 대소문자 통일
    - 빈 값 제거
    """
    normalized = {}

    for key, value in metadata.items():
        # 문자열: 공백 제거, 소문자 변환
        if isinstance(value, str):
            value = value.strip()
            if key in ['category', 'status', 'file_type']:
                value = value.lower()

        # 리스트: 중복 제거, 정렬
        elif isinstance(value, list):
            value = sorted(list(set(value)))

        # 빈 값 제거
        if value not in [None, '', [], {}]:
            normalized[key] = value

    return normalized
```

#### 팁 2: 메타데이터 템플릿

```python
# 문서 타입별 메타데이터 템플릿
METADATA_TEMPLATES = {
    'research_report': {
        'required': ['title', 'author', 'year', 'department'],
        'optional': ['project_id', 'funding_source', 'keywords'],
        'defaults': {'status': 'draft', 'language': 'ko'}
    },
    'technical_manual': {
        'required': ['title', 'version', 'product_name'],
        'optional': ['revision_date', 'manual_type'],
        'defaults': {'language': 'ko', 'format': 'PDF'}
    }
}

def create_from_template(doc_type: str, custom_values: Dict) -> Dict:
    """템플릿으로부터 메타데이터 생성"""
    template = METADATA_TEMPLATES.get(doc_type, {})

    metadata = template.get('defaults', {}).copy()
    metadata.update(custom_values)

    # 필수 필드 확인
    missing = set(template.get('required', [])) - set(metadata.keys())
    if missing:
        raise ValueError(f"Missing required fields: {missing}")

    return metadata
```

#### 팁 3: 메타데이터 마이그레이션

```python
def migrate_metadata_v1_to_v2(old_metadata: Dict) -> Dict:
    """
    메타데이터 스키마 변경 시 마이그레이션
    v1 → v2 변환 예시
    """
    new_metadata = {}

    # 필드명 변경
    field_mapping = {
        'doc_id': 'document_id',
        'create_time': 'created_at',
        'modify_time': 'updated_at'
    }

    for old_key, new_key in field_mapping.items():
        if old_key in old_metadata:
            new_metadata[new_key] = old_metadata[old_key]

    # 타입 변환
    if 'year' in old_metadata:
        # 문자열 → 정수
        new_metadata['year'] = int(old_metadata['year'])

    # 새 필드 추가
    new_metadata['schema_version'] = '2.0'
    new_metadata['migrated_at'] = datetime.now().isoformat()

    return new_metadata
```

---

## 정리

### 핵심 요약

1. **메타데이터는 "데이터에 대한 데이터"**
   - 문서의 내용이 아닌, 문서를 설명하는 정보
   - 검색, 필터링, 관리에 필수적

2. **실무 활용 이유**
   - 효율적인 문서 관리
   - 검색 성능 100배 향상
   - AI/LLM 정확도 개선
   - 데이터 품질 관리

3. **주요 사용 시나리오**
   - LLM 입력 전 사전 필터링
   - RAG 시스템의 검색 정확도 향상
   - 오류 추적 및 품질 관리

4. **실무 노하우**
   - 표준 형식 사용 (ISO 8601 등)
   - 검색 빈도 높은 필드 인덱싱
   - 메타데이터 유효성 검사
   - 버전 관리 및 변경 이력 추적

### 다음 단계

메타데이터를 생성했다면, 다음은 **임베딩 모델을 활용한 벡터화**입니다.
→ 다음 문서: [1.2.07. 임베딩 모델 활용하여 벡터화 시키기](1.2.07.임베딩%20모델%20활용하여%20벡터화%20시키기.md)

---

**문서 버전**: 1.0
**최종 수정일**: 2025-10-24
**작성자**: Bern

## 📌 다음 단계

메타데이터 생성을 익혔다면, 다음은 **임베딩 모델 활용**입니다.

**다음 문서**: [1.2.07. 임베딩 모델 활용하여 벡터화 시키기](./1.2.07.임베딩%20모델%20활용하여%20벡터화%20시키기.md)
